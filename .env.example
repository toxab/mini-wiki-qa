# ==============================================
# LLM Backend Configuration
# ==============================================
# Options: lm-studio | ollama | openai
LLM_BACKEND=lm-studio

# LM Studio (for development, GUI-based)
LM_STUDIO_MODEL=phi-3-mini-4k-instruct

# Ollama (for production, CLI-based)
OLLAMA_MODEL=phi3

# OpenAI (optional, cloud-based)
OPENAI_API_KEY=

# ==============================================
# Security
# ==============================================
API_SHARED_SECRET=change-me-in-production

# ==============================================
# Application Settings
# ==============================================
LOG_LEVEL=INFO

# ==============================================
# n8n Settings
# ==============================================
N8N_HOST=localhost
N8N_USER_MANAGEMENT_DISABLED=true

# ==============================================
# Docker Resources (for reference)
# ==============================================
# Docker Desktop → Settings → Resources:
# - CPUs: 6
# - Memory: 12GB